<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Byron J. Smith">
  <title>Reproducible bioinformatics pipelines using Make</title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" href="main.css">
</head>
<body>
<header>
<h1 class="title">Reproducible bioinformatics pipelines using <em>Make</em></h1>
<h2 class="author">Byron J. Smith</h2>
</header>
<nav id="TOC">
<ul>
<li><a href="#setup-15-minutes">Setup [15 minutes]</a></li>
<li><a href="#motivation-30-minutes">Motivation [30 minutes]</a><ul>
<li><a href="#writing-a-master-script">Writing a “master” script</a></li>
</ul></li>
<li><a href="#makefile-basics-45-minutes">Makefile basics [45 minutes]</a><ul>
<li><a href="#a-simple-makefile">A simple Makefile</a></li>
<li><a href="#running-make">Running <em>Make</em></a></li>
<li><a href="#rerunning-make">Rerunning <em>Make</em></a></li>
<li><a href="#more-recipes">More recipes</a></li>
<li><a href="#phony-targets">Phony targets</a></li>
</ul></li>
<li><a href="#make-features-45-minutes"><em>Make</em> features [45 minutes]</a><ul>
<li><a href="#parallel-make">Parallel <em>Make</em></a></li>
<li><a href="#d.r.y.-dont-repeat-yourself">D.R.Y. (Don’t Repeat Yourself)</a></li>
<li><a href="#automatic-variables">Automatic variables</a></li>
<li><a href="#pattern-rules">Pattern rules</a></li>
<li><a href="#user-defined-variables">User defined variables</a></li>
</ul></li>
<li><a href="#best-practices-for-make-based-projects-60-minutes">Best practices for <em>Make</em>-based projects [60 minutes]</a><ul>
<li><a href="#whats-a-prerequisite">What’s a prerequisite?</a></li>
<li><a href="#directory-structure">Directory structure</a><ul>
<li><a href="#store-scripts-in-scripts">Store scripts in <code>scripts/</code></a></li>
<li><a href="#hide-intermediate-files-in-data">“Hide” intermediate files in <code>data/</code></a></li>
<li><a href="#output-finished-products-to-fig">Output finished products to <code>fig/</code></a></li>
</ul></li>
<li><a href="#file-naming">File naming</a><ul>
<li><a href="#use-file-extensions-to-indicate-format">Use file extensions to indicate format</a></li>
<li><a href="#infix-processing-hints">Infix processing hints</a></li>
</ul></li>
<li><a href="#built-in-testing">Built-in Testing</a></li>
<li><a href="#review-version-control">Review: version control</a></li>
<li><a href="#exercises-left-to-the-reader">Exercises left to the reader</a></li>
</ul></li>
</ul>
</nav>
<h1 id="setup-15-minutes">Setup [15 minutes]</h1>
<p>This tutorial is designed to be run on Amazon EC2 using the Ubuntu Server 14.04 LTS image, although it should be trivial to port it for use on any other UNIX operating system. I’ve tested that everything works on an m3.medium instance. If you would like to use Windows, Git-Bash (packaged with Git for Windows) is probably your best bet, although it has not been tested on that platform.</p>
<p>For this lesson we will be using an already prepared set of files.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">curl</span> https://codeload.github.com/bsmith89/make-example/tar.gz/master \
    <span class="kw">&gt;</span> make-example-master.tgz
<span class="kw">tar</span> -xzf make-example-master.tgz
<span class="kw">cd</span> make-example-master</code></pre></div>
<p>Let’s take a look at the files we will be working with:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> apt-get update
<span class="kw">sudo</span> apt-get install tree
<span class="kw">tree</span></code></pre></div>
<p>The <code>tree</code> command produces a handy tree-diagram of the directory.</p>
<pre><code>.
├── books
│   ├── abyss.txt
│   ├── isles.txt
│   ├── last.txt
│   ├── LICENSE_TEXTS.md
│   └── sierra.txt
├── LICENSE.md
├── matplotlibrc
├── plotcount.py
├── README.md
└── wordcount.py

1 directory, 7 files</code></pre>
<p>Be sure that you also have <em>Python 3</em>, <em>Git</em>, and <em>GNU Make</em>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> apt-get install git make</code></pre></div>
<p>Configure git.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> config --global user.name <span class="st">&quot;Your Name&quot;</span>
<span class="kw">git</span> config --global user.email you@example.com</code></pre></div>
<p>Install matplotlib.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> apt-get install python3-matplotlib</code></pre></div>
<p>And, finally, load up your favorite terminal multi-plexer so we can recover if we get disconnected.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">tmux</span></code></pre></div>
<h1 id="motivation-30-minutes">Motivation [30 minutes]</h1>
<blockquote>
<p>The most frequently-occurring word occurs approximately twice as often as the second most frequent word. This is <a href="http://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s Law</a>.</p>
</blockquote>
<p>Let’s imagine that instead of computational biology we’re interested in testing Zipf’s law in some of our favorite books. We’ve compiled our raw data, the books we want to analyze (check out <code>head books/isles.txt</code>) and have prepared several Python scripts that together make up our analysis pipeline.</p>
<p>Before we begin, add a README to your project describing what we intend to do.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">nano</span> README.md
<span class="co"># Describe what you&#39;re going to do. (e.g. &quot;Test Zipf&#39;s Law&quot;)</span></code></pre></div>
<p>The first step is to count the frequency of each word in the book.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">./wordcount.py</span> books/isles.txt isles.dat</code></pre></div>
<p>Let’s take a quick peek at the result.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">head</span> -5 isles.dat</code></pre></div>
<p>shows us the top 5 lines in the output file:</p>
<pre><code>the	3822	6.7371760973
of	2460	4.33632998414
and	1723	3.03719372466
to	1479	2.60708619778
a	1308	2.30565838181</code></pre>
<p>Each row shows the word itself, the number of occurrences of that word, and the number of occurrences as a percentage of the total number of words in the text file.</p>
<p>We can do the same thing for a different book:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">./wordcount.py</span> books/abyss.txt abyss.dat
<span class="kw">head</span> -5 abyss.dat</code></pre></div>
<p>Finally, let’s visualize the results.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">./plotcount.py</span> isles.dat ascii</code></pre></div>
<p>The <code>ascii</code> argument has been added so that we get a text-based bar-plot printed to the screen.</p>
<p>The script is also able to display a graphical bar-plot using matplotlib.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">./plotcount.py</span> isles.dat show</code></pre></div>
<p>Or it can save the figure as a file.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">./plotcount.py</span> isles.dat isles.png</code></pre></div>
<p>Together these scripts implement a common workflow:</p>
<ol type="1">
<li>Read a data file.</li>
<li>Perform an analysis on this data file.</li>
<li>Write the analysis results to a new file.</li>
<li>Plot a graph of the analysis results.</li>
<li>Save the graph as an image, so we can put it in a paper.</li>
</ol>
<h2 id="writing-a-master-script">Writing a “master” script</h2>
<p>Running this pipeline for one book is pretty easy using the command-line. But once the number of files and the number of steps in the pipeline expands, this can turn into a lot of work. Plus, no one wants to sit and wait for a command to finish, even just for 30 seconds.</p>
<p>The most common solution to the tedium of data processing is to write a master script that runs the whole pipeline from start to finish.</p>
<p>We can make a new file, <code>run_pipeline.sh</code> that contains:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env bash</span>
<span class="co"># USAGE: bash run_pipeline.sh</span>
<span class="co"># to produce plots for isles and abyss.</span>

<span class="kw">./wordcount.py</span> isles.txt isles.dat
<span class="kw">./wordcount.py</span> abyss.txt abyss.dat

<span class="kw">./plotcount.py</span> isles.dat isles.png
<span class="kw">./plotcount.py</span> abyss.dat abyss.png

<span class="co"># Now archive the results in a tarball so we can share them with a colleague.</span>
<span class="kw">rm</span> -rf zipf_results
<span class="kw">mkdir</span> zipf_results
<span class="kw">mv</span> isles.dat abyss.dat isles.png abyss.png zipf_results/
<span class="kw">tar</span> -czf zipf_results.tgz zipf_results
<span class="kw">rm</span> -r zipf_results</code></pre></div>
<p>This master script solved several problems in computational reproducibility:</p>
<ol type="1">
<li>It explicitly documents our pipeline, making communication with colleagues (and our future selves) more efficient.</li>
<li>It allows us to type a single command, <code>bash run_pipeline.sh</code>, to reproduce the full analysis.</li>
<li>It prevents us from <em>repeating</em> typos or mistakes. You might not get it right the first time, but once you fix something it’ll (probably) stay that way.</li>
</ol>
<p>To continue with the Good Ideas, let’s put everything under version control.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> init
<span class="kw">git</span> add README.md
<span class="kw">git</span> commit -m <span class="st">&quot;Starting a new project.&quot;</span>
<span class="kw">git</span> add wordcount.py plotcount.py matplotlibrc
<span class="kw">git</span> commit -m <span class="st">&quot;Write scripts to test Zipf&#39;s law.&quot;</span>
<span class="kw">git</span> add run_pipeline.sh
<span class="kw">git</span> commit -m <span class="st">&quot;Write a master script to run the pipeline.&quot;</span></code></pre></div>
<p>Notice that I didn’t version control any of the products of our analysis. I’ll talk more about this later.</p>
<p>A master script is a good start, but it has a few shortcomings.</p>
<p>Let’s imagine that we adjusted the width of the bars in our plot produced by <code>plotcount.py</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">nano</span> plotcount.py
<span class="co"># In the definition of plot_word_counts replace:</span>
<span class="co">#    width = 1.0</span>
<span class="co"># with:</span>
<span class="co">#    width = 0.8</span>
<span class="kw">git</span> add plotcount.py
<span class="kw">git</span> commit -m <span class="st">&quot;Fix the bar width.&quot;</span></code></pre></div>
<p>Now we want to recreate our figures. We <em>could</em> just <code>bash run_pipeline.sh</code> again. That would work, but it could also be a big pain if counting words takes more than a few seconds. The word counting routine hasn’t changed; we shouldn’t need to recreate those files.</p>
<p>Alternatively, we could manually rerun the plotting for each word-count file and recreate the tarball.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">file</span> in *.dat<span class="kw">;</span> <span class="kw">do</span>
    <span class="kw">./plotcount.py</span> <span class="ot">$file</span> <span class="ot">${file/</span>.dat<span class="ot">/</span>.png<span class="ot">}</span>
<span class="kw">done</span>

<span class="kw">rm</span> -rf zipf_results
<span class="kw">mkdir</span> zipf_results
<span class="kw">mv</span> isles.dat abyss.dat isles.png abyss.png zipf_results/
<span class="kw">tar</span> -czf zipf_results.tgz zipf_results
<span class="kw">rm</span> -r zipf_results</code></pre></div>
<p>But then we don’t get many of the benefits of having a master script in the first place.</p>
<p>Another popular option is to comment out a subset of the lines in <code>run_pipeline.sh</code>:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env bash</span>
<span class="co"># USAGE: bash run_pipeline.sh</span>
<span class="co"># to produce plots for isles and abyss.</span>

<span class="co"># These lines are commented out because they don&#39;t need to be rerun.</span>
<span class="co">#./wordcount.py isles.txt isles.dat</span>
<span class="co">#./wordcount.py abyss.txt abyss.dat</span>

<span class="kw">./plotcount.py</span> isles.dat isles.png
<span class="kw">./plotcount.py</span> abyss.dat abyss.png

<span class="co"># Now archive the results in a tarball so we can share them with a colleague.</span>
<span class="kw">rm</span> -rf zipf_results
<span class="kw">mkdir</span> zipf_results
<span class="kw">mv</span> isles.dat abyss.dat isles.png abyss.png zipf_results/
<span class="kw">tar</span> -czf zipf_results.tgz zipf_results
<span class="kw">rm</span> -r zipf_results</code></pre></div>
<p>Followed by <code>bash run_pipeline.sh</code>.</p>
<p>But this process, and subsequently undoing it, can be a hassle and source of errors in complicated pipelines.</p>
<p>What we really want is an executable <em>description</em> of our pipeline that allows software to do the tricky part for us: figuring out what steps need to be rerun. It would also be nice if this tool encourage a <em>modular</em> analysis and reusing instead of rewriting parts of our pipeline. As an added benefit, we’d like it all to play nice with the other mainstays of reproducible research: version control, Unix-style tools, and a variety of scripting languages.</p>
<h1 id="makefile-basics-45-minutes">Makefile basics [45 minutes]</h1>
<p><em>Make</em> is a computer program originally designed to automate the compilation and installation of software. <em>Make</em> automates the process of building target files through a series of discrete steps. Despite it’s original purpose, this design makes it a great fit for bioinformatics pipelines, which often work by transforming data from one form to another (e.g. <em>raw data</em> → <em>word counts</em> → <em>???</em> → <em>profit</em>).</p>
<p>For this tutorial we will be using an implementation of <em>Make</em> called <em>GNU Make</em>, although others exist.</p>
<h2 id="a-simple-makefile">A simple Makefile</h2>
<p>Let’s get started writing a description of our analysis for <em>Make</em>.</p>
<p>Open up a file called <code>Makefile</code> in your editor of choice (e.g. <code>nano Makefile</code>) and add the following:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">isles.dat:</span><span class="dt"> books/isles.txt</span>
	./wordcount.py books/isles.txt isles.dat</code></pre></div>
<p>We have now written the simplest, non-trivial Makefile. It is pretty reminiscent of one of the lines from our master script. It is a good bet that you can figure out what this Makefile does.</p>
<p>Be sure to notice a few syntactical items.</p>
<p>The part before the colon is called the <strong>target</strong> and the part after is our list of <strong>prerequisites</strong> (there is just one in this case). This first line is followed by an indented section called the <strong>recipe</strong>. The whole thing is together called a <strong>rule</strong>.</p>
<p>Notice that the indent is <em>not</em> multiple spaces, but is instead a single tab character. This is the first gotcha in makefiles. If the difference between spaces and a tab character isn’t obvious in your editor of choice, try moving your cursor from one side of the tab to the other. It should <em>jump</em> four or more spaces. If your recipe is not indented with a tab character it is likely to not work.</p>
<p>Notice that this recipe is exactly the same as the analogous step in our master shell script. This is no coincidence; <em>Make</em> recipes <em>are</em> shell scripts. The first line (<em>target</em>: <em>prerequisites</em>) explicitly declares two details that were implicit in our pipeline script:</p>
<ol type="1">
<li>We are generating a file called <code>isles.dat</code></li>
<li>Creating this file requires <code>books/isles.txt</code></li>
</ol>
<p>We’ll think about our pipeline as a network of files that are dependent on one another. Right now our Makefile describes a pretty simple <strong>dependency graph</strong>.</p>
<blockquote>
<p><code>books/isles.txt</code> → <code>isles.dat</code></p>
</blockquote>
<p>where the “→” is pointing from requirements to targets.</p>
<p>Don’t forget to commit:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add Makefile
<span class="kw">git</span> commit -m <span class="st">&quot;Start converting master script into a Makefile.&quot;</span></code></pre></div>
<h2 id="running-make">Running <em>Make</em></h2>
<p>Now that we have a (currently incomplete) description of our pipeline, let’s use <em>Make</em> to execute it.</p>
<p>First, remove the previously generated files.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">rm</span> *.dat *.png</code></pre></div>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">make</span> isles.dat</code></pre></div>
<blockquote>
<h4 id="aside">Aside</h4>
<p>Notice that we didn’t tell <em>Make</em> to use <code>Makefile</code>. When you run <code>make</code>, the program automatically looks in several places for your Makefile. While other filenames will work, it is Good Idea to always call your Makefile <code>Makefile</code>.</p>
</blockquote>
<p>You should see the following print to the terminal:</p>
<pre><code>./wordcount.py books/isles.txt isles.dat</code></pre>
<p>By default, <em>Make</em> prints the recipes that it executes.</p>
<p>Let’s see if we got what we expected.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">head</span> -5 isles.dat</code></pre></div>
<p>The first 5 lines of that file should look exactly like before.</p>
<h2 id="rerunning-make">Rerunning <em>Make</em></h2>
<p>Let’s try running <em>Make</em> the same way again.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">make</span> isles.dat</code></pre></div>
<p>This time, instead of executing the same recipe, <em>Make</em> prints <code>make: Nothing to be done for 'isles.dat'.</code></p>
<p>What’s happening here?</p>
<p>When you ask <em>Make</em> to make <code>isles.dat</code> it first looks at the modification time of that target. Next it looks at the modification time for the target’s prerequisites. If the target is newer than the prerequisites <em>Make</em> decides that the target is up-to-date and does not need to be remade.</p>
<p>Much has been said about using modification times as the cue for remaking files. This can be another <em>Make</em> gotcha, so keep it in mind.</p>
<p>If you want to induce the original behavior, you just have to change the modification time of <code>books/isles.txt</code> so that it is newer than <code>isles.dat</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">touch</span> books/isles.txt
<span class="kw">make</span> isles.dat</code></pre></div>
<p>The original behavior is restored.</p>
<p>Sometimes you just want <em>Make</em> to tell you what it thinks about the current state of your files. <code>make --dry-run isles.dat</code> will print <em>Make</em>’s execution plan, without actually carrying it out. The flag can be abbreviated as <code>-n</code>.</p>
<p>If you don’t pass a target as an argument to make (i.e. just run <code>make</code>) it will assume that you want to build the first target in the Makefile.</p>
<h2 id="more-recipes">More recipes</h2>
<p>Now that <em>Make</em> knows how to build <code>isles.dat</code>, we can add a rule for plotting those results.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">isles.png:</span><span class="dt"> isles.dat</span>
	./plotcount.py isles.dat isles.png</code></pre></div>
<p>The dependency graph now looks like:</p>
<blockquote>
<p><code>books/isles.txt</code> → <code>isles.dat</code> → <code>isles.png</code></p>
</blockquote>
<p>Let’s add a few more recipes to our Makefile.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">abyss.dat:</span><span class="dt"> books/abyss.txt</span>
	./wordcount.py books/abyss.txt abyss.dat

<span class="dv">zipf_results.tgz:</span><span class="dt"> isles.dat abyss.dat isles.png abyss.png</span>
	rm -rf zipf_results/
	mkdir zipf_results/
	cp isles.dat abyss.dat isles.png abyss.png zipf_results/
	tar -czf zipf_results.tgz zipf_results/
	rm -r zipf_results/</code></pre></div>
<p>And commit the changes.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add Makefile
<span class="kw">git</span> commit -m <span class="st">&quot;Add recipes for abyss counts, isles plotting, and the final archive.&quot;</span></code></pre></div>
<p>Here the recipe for <code>zipf_results.tgz</code> involves running a series of shell commands. When building the archive, <em>Make</em> will run each line successively unless any return an error.</p>
<blockquote>
<h4 id="question">Question</h4>
<p>Without doing it, what happens if you run <code>make isles.png</code>?</p>
</blockquote>
<blockquote>
<h4 id="challenge">Challenge</h4>
<p>What does the dependency graph look like for your Makefile?</p>
</blockquote>
<blockquote>
<h4 id="try-it">Try it</h4>
<p>What happens if you run <code>make zipf_results.tgz</code> right now?</p>
</blockquote>
<blockquote>
<h4 id="practice">Practice</h4>
<p>Write a recipe for <code>abyss.png</code>.</p>
</blockquote>
<p>Once you’ve written a recipe for <code>abyss.png</code> you should be able to run <code>make zipf_results.tgz</code>.</p>
<p>Let’s delete all of our files and try it out.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">rm</span> abyss.* isles.*
<span class="kw">make</span> zipf_results.tgz</code></pre></div>
<p>You should get the something like the following output (the order may be different) to your terminal:</p>
<pre><code>./wordcount.py books/abyss.txt abyss.dat
./wordcount.py books/isles.txt isles.dat
./plotcount.py abyss.dat abyss.png
./plotcount.py isles.dat isles.png
rm -rf zipf_results/
mkdir zipf_results/
cp isles.dat abyss.dat isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results/
rm -r zipf_results/</code></pre>
<p>Since you asked for <code>zipf_results.tgz</code> <em>Make</em> looked first for that file. Not finding it, <em>Make</em> looked for its prerequisites. Since none of those existed it remade the ones it could, <code>abyss.dat</code> and <code>isles.dat</code>. Once those were finished it was able to make <code>abyss.png</code> and <code>isles.png</code>, before finally building <code>zipf_results.tgz</code>.</p>
<blockquote>
<h4 id="try-it-1">Try it</h4>
<p>What happens if you <code>touch abyss.dat</code> and then <code>make zipf_results.tgz</code>?</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add Makefile
<span class="kw">git</span> commit -m <span class="st">&quot;Finish translating pipeline script to a Makefile.&quot;</span>
<span class="kw">git</span> status</code></pre></div>
<p>Notice all the files that <em>Git</em> wants to be tracking? Like I said before, we’re not going to version control any of the intermediate or final products of our pipeline. To reflect this fact add a <code>.gitignore</code> file:</p>
<pre class=".gitignore"><code>*.dat
*.png
zipf_results.tgz
LICENSE.md</code></pre>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add .gitignore
<span class="kw">git</span> commit -m <span class="st">&quot;Have git ignore intermediate data files.&quot;</span>
<span class="kw">git</span> status</code></pre></div>
<h2 id="phony-targets">Phony targets</h2>
<p>Sometimes its nice to have targets that don’t refer to actual files.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">all:</span><span class="dt"> isles.png abyss.png zipf_results.tgz</span></code></pre></div>
<p>Even though this rule doesn’t have a recipe, it does have prerequisites. Now, when you run <code>make all</code> <em>Make</em> will do what it needs to to bring all three of those targets up to date.</p>
<p>It is traditional for “<code>all:</code>” to be the first recipe in a makefile, since the first recipe is what is built by default when no other target is passed as an argument.</p>
<p>Another traditional target is “<code>clean</code>”. Add the following to your Makefile.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">clean:</span>
	rm --force *.dat *.png zipf_results.tgz</code></pre></div>
<p>Running <code>make clean</code> will now remove all of the cruft.</p>
<p>Watch out, though!</p>
<blockquote>
<h4 id="try-it-2">Try it</h4>
<p>What happens if you create a file named <code>clean</code> (i.e. <code>touch clean</code>) and then run <code>make clean</code>?</p>
</blockquote>
<p>When you run <code>make clean</code> you get <code>make: Nothing to be done for 'clean'.</code>. That’s <em>not</em> because all those files have already been removed. <em>Make</em> isn’t that smart. Instead, make sees that there is already a file named “<code>clean</code>” and, since this file is newer than all of its prerequisites (there are none), <em>Make</em> decides there’s nothing left to do.</p>
<p>To avoid this problem add the following to your Makefile.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="ot">.PHONY:</span><span class="dt"> all clean</span></code></pre></div>
<p>This “special target” tells <em>Make</em> to assume that the targets “all”, and “clean” are <em>not</em> real files; they’re <strong>phony</strong> targets.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add Makefile
<span class="kw">git</span> commit -m <span class="st">&quot;Added &#39;all&#39; and &#39;clean&#39; recipes.&quot;</span></code></pre></div>
<h1 id="make-features-45-minutes"><em>Make</em> features [45 minutes]</h1>
<p>Right now our Makefile looks like this:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="co"># Dummy targets</span>
<span class="dv">all:</span><span class="dt"> isles.png abyss.png zipf_results.tgz</span>

<span class="dv">clean:</span>
	rm --force *.dat *.png zipf_results.tgz

<span class="ot">.PHONY:</span><span class="dt"> all clean</span>

<span class="co"># Analysis and plotting</span>
<span class="dv">isles.dat:</span><span class="dt"> books/isles.txt</span>
	./wordcount.py books/isles.txt isles.dat

<span class="dv">isles.png:</span><span class="dt"> isles.dat</span>
	./plotcount.py isles.dat isles.png

<span class="dv">abyss.dat:</span><span class="dt"> books/abyss.txt</span>
	./wordcount.py books/abyss.txt abyss.dat

<span class="dv">abyss.png:</span><span class="dt"> abyss.png</span>
	./plotcount.py abyss.dat abyss.png

<span class="co"># Archive for sharing</span>
<span class="dv">zipf_results.tgz:</span><span class="dt"> isles.dat abyss.dat isles.png abyss.png</span>
	rm -rf zipf_results/
	mkdir zipf_results/
	cp isles.dat abyss.dat isles.png abyss.png zipf_results/
	tar -czf zipf_results.tgz zipf_results/
	rm -r zipf_results/</code></pre></div>
<p>Looks good, don’t you think? Notice the added comments, starting with the “<code>#</code>” character just like in Python, R, shell, etc.</p>
<p>Using these recipes, a simple call to <code>make</code> builds all the same files that we were originally making either manually or using the master script, but with a few bonus features.</p>
<p>Now, if we change one of the inputs, we don’t have to rebuild everything. Instead, <em>Make</em> knows to only rebuild the files that, either directly or indirectly, depend on the file that changed. This is called an <strong>incremental build</strong>. It’s no longer our job to track those dependencies. One fewer cognitive burden getting in the way of research progress!</p>
<p>In addition, a makefile explicitly documents the inputs to and outputs from every step in the analysis. These are like informal “USAGE:” documentation for our scripts.</p>
<h2 id="parallel-make">Parallel <em>Make</em></h2>
<p>And check this out!</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">make</span> clean
<span class="kw">make</span> --jobs</code></pre></div>
<p>Did you see it? The <code>--jobs</code> flag (just <code>-j</code> works too) tells <em>Make</em> to run recipes in <em>parallel</em>. Our dependency graph clearly shows that <code>abyss.dat</code> and <code>isles.dat</code> are mutually independent and can both be built at the same time. Likewise for <code>abyss.png</code> and <code>isles.png</code>. If you’ve got a bunch of independent branches in your analysis, this can greatly speed up your build process.</p>
<h2 id="d.r.y.-dont-repeat-yourself">D.R.Y. (Don’t Repeat Yourself)</h2>
<p>In many programming language, the bulk of the language features are there to allow the programmer to describe long-winded computational routines as short, expressive, beautiful code. Features in Python or R like user-defined variables and functions are useful in part because they mean we don’t have to write out (or think about) all of the details over and over again. This good habit of writing things out only once is known as the D.R.Y. principle.</p>
<p>In <em>Make</em> a number of features are designed to minimize repetitive code. Our current makefile does <em>not</em> conform to this principle, but <em>Make</em> is perfectly capable of solving the problem.</p>
<h2 id="automatic-variables">Automatic variables</h2>
<p>One overly repetitive part of our Makefile: Targets and prerequisites are in both the header <em>and</em> the recipe of each rule.</p>
<p>It turns out, that</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">isles.dat:</span><span class="dt"> books/isles.txt</span>
	./wordcount.py books/isles.txt isles.dat</code></pre></div>
<p>can be rewritten as</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">isles.dat:</span><span class="dt"> books/isles.txt</span>
	./wordcount.py <span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>Here we’ve replaced the prerequisite “<code>books/isles.txt</code>” in the recipe with “<code>$^</code>” and the target “<code>isles.dat</code>” with “<code>$@</code>”. Both “<code>$^</code>” and “<code>$@</code>” are variables that refer to all of the prerequisites and target of a rule, respectively. In <em>Make</em>, variables are referenced with a leading dollar sign symbol. While we can also define our own variables, <em>Make</em> <em>automatically</em> defines a number of variables, including each of these.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">zipf_results.tgz:</span><span class="dt"> isles.dat abyss.dat isles.png abyss.png</span>
	rm -rf zipf_results/
	mkdir zipf_results/
	cp isles.dat abyss.dat isles.png abyss.png zipf_results/
	tar -czf zipf_results.tgz zipf_results/
	rm -r zipf_results/</code></pre></div>
<p>can now be rewritten as</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">zipf_results.tgz:</span><span class="dt"> isles.dat abyss.dat isles.png abyss.png</span>
	rm -rf zipf_results/
	mkdir zipf_results/
	cp <span class="ch">$^</span> zipf_results/
	tar -czf <span class="ch">$@</span> zipf_results/
	rm -r zipf_results/</code></pre></div>
<p>Phew! That’s much less cluttered, and still perfectly understandable once you know what the variables mean.</p>
<blockquote>
<h4 id="try-it-3">Try it</h4>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">make</span> clean
<span class="kw">make</span> isles.dat</code></pre></div>
<!--Those extra backticks are because of Vim syntax highlighting.-->
</blockquote>
<p>You should get the same output as last time. Internally, <em>Make</em> replaced “<code>$@</code>” with “<code>isles.dat</code>” and “<code>$^</code>” with “<code>books/isles.txt</code>” before running the recipe.</p>
<blockquote>
<h4 id="practice-1">Practice</h4>
<p>Go ahead and rewrite all of the rules in your Makefile to minimize repetition and take advantage of these automatic variables. Don’t forget to commit your work.</p>
</blockquote>
<h2 id="pattern-rules">Pattern rules</h2>
<p>Another deviation from D.R.Y.: We have nearly identical recipes for <code>abyss.dat</code> and <code>isles.dat</code>.</p>
<p>It turns out we can replace <em>both</em> of those rules with just one rule, by telling <em>Make</em> about the relationships between filename <em>patterns</em>.</p>
<p>A “pattern rule” looks like this:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">%.dat:</span><span class="dt"> books/%.txt</span>
	countwords.py <span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>Here we’ve replaced the book name with a percent sign, “<code>%</code>”. The “<code>%</code>” is called the <strong>stem</strong> and matches any sequence of characters in the target. (Kind of like a “<code>*</code>” (glob) in a path name, but they are <em>not</em> the same.) Whatever it matches is then filled in to the prerequisites wherever there’s a “<code>%</code>”.</p>
<p>This rule can be interpreted as:</p>
<blockquote>
<p>In order to build a file named <code>[something].dat</code> (the target) find a file named <code>books/[that same something].txt</code> (the prerequisite) and run <code>countwords.py [the prerequisite] [the target]</code>.</p>
</blockquote>
<p>Notice how helpful the automatic variables are here. This recipe will work no matter what stem is being matched!</p>
<p>We can replace <em>both</em> of the rules that matched this pattern (<code>abyss.dat</code> and <code>isles.dat</code>) with just one rule. Go ahead and do that in your Makefile.</p>
<blockquote>
<h4 id="try-it-4">Try it</h4>
<p>After you’ve replaced the two rules with one pattern rule, try removing all of the products (<code>make clean</code>) and rerunning the pipeline.</p>
<p>Is anything different now that you’re using the pattern rule?</p>
<p>If everything still works, commit your changes to <em>Git</em>.</p>
</blockquote>
<blockquote>
<h4 id="practice-2">Practice</h4>
<p>Replace the recipes for <code>abyss.png</code> and <code>isles.png</code> with a single pattern rule.</p>
</blockquote>
<blockquote>
<h4 id="challenge-1">Challenge</h4>
<p>Add <code>books/sierra.txt</code> to your pipeline.</p>
<p>(i.e. <code>make all</code> should plot the word counts and add the plots to <code>zipf_results.tgz</code>)</p>
</blockquote>
<p>Commit your changes to <em>Git</em> before we move on.</p>
<h2 id="user-defined-variables">User defined variables</h2>
<p>Not all variables in a makefile are of the automatic variety. Users can define their own, as well.</p>
<p>Add this lines at the top of your makefile:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dt">ARCHIVED </span><span class="ch">:=</span><span class="st"> isles.dat isles.png </span><span class="ch">\</span>
<span class="st">            abyss.dat abyss.png </span><span class="ch">\</span>
<span class="st">            sierra.dat sierra.png</span></code></pre></div>
<p>Just like many other languages, in makefiles “<code>\</code>” is a line-continuation character. Think of this variable definition as a single line without the backslash.</p>
<p>The variable <code>ARCHIVED</code> is a list of the files that we want to include in our tarball. Now wherever we write <code>${ARCHIVED}</code> it will be replaced with that list of files. The dollar sign, “<code>$</code>”, and curly-braces, “<code>{}</code>”, are both mandatory when inserting the contents of a variable.</p>
<p>Notice the backslashes in the variable definition splitting the list over three lines, instead of one very long line. Also notice that we assigned to the variable with “<code>:=</code>”. This is generally a Good Idea; Assigning with a normal equals sign can result in non-intuitive behavior (for reasons we may not talk about). Finally, notice that the items in our list are separated by <em>whitespace</em>, not commas. Prerequisite lists were the same way; this is just how lists of things work in makefiles. If you included commas they would be considered parts of the filenames.</p>
<p>Using this variable we can replace the prerequisites of <code>zipf_results.tgz</code>. That rule would now be:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">zipf_results.tgz:</span><span class="dt"> </span><span class="ch">${</span><span class="dt">ARCHIVED</span><span class="ch">}</span>
	rm -rf zipf_results/
	mkdir zipf_results/
	cp <span class="ch">$^</span> zipf_results/
	tar -czf <span class="ch">$@</span> zipf_results/
	rm -r zipf_results/</code></pre></div>
<p>We can also use <code>${ARCHIVED}</code> to simplify our cleanup rule.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">clean:</span>
	rm --force <span class="ch">${</span><span class="dt">ARCHIVED</span><span class="ch">}</span> zipf_results.tgz</code></pre></div>
<blockquote>
<h4 id="try-it-5">Try it</h4>
<p>Try running <code>clean</code> and then <code>all</code>.</p>
<p>Does everything still work?</p>
</blockquote>
<h1 id="best-practices-for-make-based-projects-60-minutes">Best practices for <em>Make</em>-based projects [60 minutes]</h1>
<p>A Makefile can be an important part of a reproducible research pipeline. Have you noticed how simple it is now to add/remove books from our analysis? Just add or remove those files from the definition of <code>ARCHIVED</code> or the prerequisites for the <code>all</code> target! With the master script <code>run_pipeline.sh</code>, adding a third book required either more complicated or less transparent changes.</p>
<h2 id="whats-a-prerequisite">What’s a prerequisite?</h2>
<p>We’ve talked a lot about the power of <em>Make</em> for rebuilding research outputs when input data changes. When doing novel data analysis, however, it’s very common for our <em>scripts</em> to be as or <em>more</em> dynamic than the data.</p>
<p>What happens when we edit our scripts instead of changing our data?</p>
<blockquote>
<h4 id="try-it-6">Try it</h4>
<p>First, run <code>make all</code> so your analysis is up-to-date.</p>
<p>Let’s change the default number of entries in the rank/frequency plot from 10 to 5.</p>
<p>(Hint: edit the function definition for <code>plot_word_counts</code> in <code>plotcounts.py</code> to read <code>limit=5</code>.)</p>
<p>Now run <code>make all</code> again. What happened?</p>
</blockquote>
<p>As it stands, we have to run <code>make clean</code> followed by <code>make all</code> to update our analysis with the new script. We’re missing out on the benefits of incremental analysis when our scripts are changing too.</p>
<p>There must be a better way…and there is! Scripts should be prerequisites too.</p>
<p>Let’s edit the pattern rule for <code>%.png</code> to include <code>plotcounts.py</code> as a prerequisites.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">%.png:</span><span class="dt"> plotcounts.py %.dat</span>
	<span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>The header makes sense, but that’s a strange looking recipe: just two automatic variables.</p>
<p>This recipe works because “<code>$^</code>” is replaced with all of the prerequisites. <em>In order</em>. When building <code>abyss.png</code>, for instance, it is replaced with <code>plotcounts.py abyss.dat</code>, which is actually exactly what we want.</p>
<blockquote>
<h4 id="try-it-7">Try it</h4>
<p>What happens when you run the pipeline after modifying your script again?</p>
<p>(Changes to your script can be simulated with <code>touch plotcounts.py</code>.)</p>
</blockquote>
<blockquote>
<h4 id="practice-3">Practice</h4>
<p>Update your other rules to include the relevant scripts as prerequisites.</p>
<p>Commit your changes.</p>
</blockquote>
<h2 id="directory-structure">Directory structure</h2>
<p>Take a look at all of the clutter in your project directory (run <code>ls</code> to list all of the files). For such a small project that’s a lot of junk! Imagine how hard it would be to find your way around this analysis if you had more than three steps? Let’s move some stuff around to make our project easier to navigate.</p>
<h3 id="store-scripts-in-scripts">Store scripts in <code>scripts/</code></h3>
<p>First we’ll stow away the scripts.</p>
<pre><code>mkdir scripts/
mv plotcounts.py wordcount.py scripts/</code></pre>
<p>We also need to update our Makefile to reflect the change:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">%.dat:</span><span class="dt"> countwords.py books/%.txt</span>
	<span class="ch">$^</span> <span class="ch">$@</span>

<span class="dv">%.png:</span><span class="dt"> plotcounts.py %.dat</span>
	<span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>becomes:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">%.dat:</span><span class="dt"> scripts/countwords.py books/%.txt</span>
	<span class="ch">$^</span> <span class="ch">$@</span>

<span class="dv">%.png:</span><span class="dt"> scripts/plotcounts.py %.dat</span>
	<span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>That’s a little more verbose, but it is now explicit that <code>countwords.py</code> and <code>plotcount.py</code> are scripts.</p>
<p><em>Git</em> should have no problem with the move once you tell it which files to be aware of.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add countwords.py plotcounts.py
<span class="kw">git</span> add scripts/countwords.py scripts/plotcounts.py
<span class="kw">git</span> add Makefile
<span class="kw">git</span> commit -m <span class="st">&quot;Move scripts into a subdirectory.&quot;</span></code></pre></div>
<p>Great! From here on, when we add new scripts to our analysis they won’t clutter up our project root.</p>
<h3 id="hide-intermediate-files-in-data">“Hide” intermediate files in <code>data/</code></h3>
<p>Speaking of clutter, what are we gonna do about all of these intermediate files!? Put ’em in a subdirectory!</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">mkdir</span> data/
<span class="kw">mv</span> *.tsv data/</code></pre></div>
<p>And then fix up your Makefile. Adjust the relevant lines to look like this.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="co"># ...</span>

<span class="dt">ARCHIVED </span><span class="ch">:=</span><span class="st"> data/isles.dat isles.png </span><span class="ch">\</span>
<span class="st">            data/abyss.dat abyss.png </span><span class="ch">\</span>
<span class="st">            data/sierra.dat sierra.png</span>

<span class="co"># ...</span>

<span class="dv">data/%.dat:</span><span class="dt"> scripts/countwords.py books/%.txt</span>
	<span class="ch">$^</span> <span class="ch">$@</span>

<span class="dv">%.png:</span><span class="dt"> scripts/plotcounts.py data/%.dat</span>

<span class="co"># ...</span></code></pre></div>
<p>Thanks to our <code>ARCHIVED</code> variable, making these changes is pretty simple.</p>
<p>We have to make one more change if we don’t want <em>Git</em> to bother us about untracked files. Update your <code>.gitignore</code>.</p>
<pre class=".gitignore"><code>data/*.dat
*.png
zipf_results.tgz
LICENSE.md</code></pre>
<p>Now commit your changes.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add Makefile
<span class="kw">git</span> add .gitignore</code></pre></div>
<p>Simple!</p>
<h3 id="output-finished-products-to-fig">Output finished products to <code>fig/</code></h3>
<blockquote>
<h4 id="practice-4">Practice</h4>
<p>Move the plots and <code>zipf_results.tgz</code> to a directory called <code>fig/</code>.</p>
</blockquote>
<p>You can call this directory something else if you prefer, but <code>fig/</code> seems short and descriptive.</p>
<blockquote>
<h4 id="try-it-8">Try it</h4>
<p>Does your pipeline still execute the way you expect?</p>
</blockquote>
<h2 id="file-naming">File naming</h2>
<h3 id="use-file-extensions-to-indicate-format">Use file extensions to indicate format</h3>
<p>Up to this point, we’ve been working with three types of data files, each with it’s own file extension.</p>
<ul>
<li>‘<code>.txt</code>’ files: the original book in plain-text</li>
<li>‘<code>.dat</code>’ files: word counts and percentages in a plain-text format</li>
<li>‘<code>.png</code>’ files: PNG formatted barplots</li>
</ul>
<p>Using file extensions like these clearly indicates to anyone not familiar with your project what software to view each file with; you won’t get much out of opening a PNG with a text editor. Whenever possible, use a widely used extension to make it easy for others to understand your data.</p>
<p>File extensions also give us a handle for describing the flow of data in our pipeline. Pattern rules rely on this convention. Our makefile says that the raw, book data feeds into word count data which feeds into barplot data.</p>
<p>But the current naming scheme has one obvious ambiguity: ‘<code>.dat</code>’ isn’t particularly descriptive. Lots of file formats can be described as “data”, including binary formats that would require specialized software to view. For tab-delimited, tabular data (data in rows and columns), ‘<code>.tsv</code>’ is a more precise convention.</p>
<p>Updating our pipeline to use this extension is as simple as find-and-replace ‘<code>.dat</code>’ to ‘<code>.tsv</code>’ in our Makefile. If you’re tired of <code>mv</code>-ing your files every time you change your pipeline you can also <code>make clean</code> followed by <code>make all</code> to check that everything still works.</p>
<p>You might want to update your “<code>clean</code>” recipe to remove all the junk like so:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">clean:</span>
	rm -f data/* fig/*</code></pre></div>
<p>Be sure to commit all of your changes.</p>
<h3 id="infix-processing-hints">Infix processing hints</h3>
<p>One of our goals in implementing best practices for our analysis pipeline is to make it easy to change it without rewriting everything. Let’s add a preprocessing step to our analysis that puts everything in lowercase before counting words.</p>
<p>The program <code>tr</code> (short for “translate”) is a Unix-style filter that swaps one set of characters for another. <code>tr '[:upper:]' '[:lower:]' &lt; [input file] &gt; [output file]</code> will read the mixedcase input file and write all lowercase to the output file.</p>
<p>We can add this to our pipeline by first adding a rule. We know the recipe is going to look like this:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">tr &#39;[:</span><span class="dt">upper:]&#39; &#39;[:lower:]&#39; &lt; </span><span class="ch">$^</span><span class="dt"> &gt; </span><span class="ch">$@</span></code></pre></div>
<blockquote>
<h4 id="challenge-2">Challenge</h4>
<p>Rewrite your Makefile to update the pipeline with the preprocessing step.</p>
</blockquote>
<p>You probably decided to take the pattern <code>books/%.txt</code> as the prerequisite, but what did you opt to name the target?</p>
<p><code>data/%.txt</code> is an option, but that means we have two files named <code>[bookname].txt</code>, one in <code>books/</code> and one in <code>data/</code>. Probably not the easiest to differentiate.</p>
<p>A better option is to use a more descriptive filename.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">data/%.lower.txt:</span><span class="dt"> books/%.txt</span>
	tr <span class="st">&#39;[:upper:]&#39;</span> <span class="st">&#39;[:lower:]&#39;</span> &lt; <span class="ch">$^</span> &gt; <span class="ch">$@</span></code></pre></div>
<p>By including an <strong>infix</strong> of <code>.lower.</code> in our filename it’s easy to see that one file is a lowercase version of the mixedcase original. Now we can extend our pipeline with a variety of pre- and post-processing steps, give each of them a descriptive infix, and the names will be a self-documenting record of its origins.</p>
<p>For reasons which will be explained in a minute, let’s also make a dummy preprocessing step which will just copy the books verbatim into our <code>data/</code> directory.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">data/%.txt:</span><span class="dt"> books/%.txt</span>
	cp <span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>And, in the spirit of infixes, we’ll rename <code>data/%.tsv</code> to be more descriptive.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">data/%.counts.tsv:</span><span class="dt"> scripts/wordcount.py data/%.txt</span>
	<span class="ch">$^</span> <span class="ch">$@</span>

<span class="dv">fig/%.counts.png:</span><span class="dt"> scripts/plotcount.py data/%.counts.tsv</span>
    <span class="ch">$^</span> <span class="ch">$@</span></code></pre></div>
<p>Here’s the <em>full</em> Makefile:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dt">ARCHIVED </span><span class="ch">:=</span><span class="st"> data/isles.lower.counts.tsv data/abyss.lower.counts.tsv </span><span class="ch">\</span>
<span class="st">            data/sierra.lower.counts.tsv fig/isles.lower.counts.png </span><span class="ch">\</span>
<span class="st">            fig/abyss.lower.counts.png fig/sierra.lower.counts.png</span>

<span class="co"># Dummy targets</span>
<span class="dv">all:</span><span class="dt"> fig/isles.lower.counts.png fig/abyss.lower.counts.png </span><span class="ch">\</span>
<span class="dt">        fig/sierra.lower.counts.png zipf_results.tgz</span>

<span class="dv">clean:</span>
	rm --force data/* fig/*

<span class="ot">.PHONY:</span><span class="dt"> all clean</span>

<span class="co"># Analysis and plotting</span>
<span class="dv">data/%.txt:</span><span class="dt"> books/%.txt</span>
	cp <span class="ch">$^</span> <span class="ch">$@</span>

<span class="dv">data/%.lower.txt:</span><span class="dt"> data/%.txt</span>
	tr <span class="st">&#39;[:upper:]&#39;</span> <span class="st">&#39;[:lower:]&#39;</span> &lt; <span class="ch">$^</span> &gt; <span class="ch">$@</span>

<span class="dv">data/%.counts.tsv:</span><span class="dt"> scripts/wordcount.py data/%.txt</span>
	<span class="ch">$^</span> <span class="ch">$@</span>

<span class="dv">fig/%.counts.png:</span><span class="dt"> scripts/plotcount.py data/%.counts.tsv</span>
	<span class="ch">$^</span> <span class="ch">$@</span>

<span class="co"># Archive for sharing</span>
<span class="dv">zipf_results.tgz:</span><span class="dt"> </span><span class="ch">${</span><span class="dt">ARCHIVED</span><span class="ch">}</span>
	rm -rf zipf_results/
	mkdir zipf_results/
	cp <span class="ch">$^</span> zipf_results/
	tar -czf <span class="ch">$@</span> zipf_results/
	rm -r zipf_results/</code></pre></div>
<p>Our filenames are certainly more verbose now, but in exchange we get:</p>
<ol type="1">
<li>self-documenting filenames</li>
<li>more flexible development</li>
<li>and something else, too…</li>
</ol>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">make</span> clean
<span class="kw">make</span> fig/abyss.lower.counts.png fig/abyss.counts.png</code></pre></div>
<p>What happened there? We just built two different barplots, one for our analysis <em>with</em> the preprocessing step and one <em>without</em>. Both from the same Makefile. By liberally applying pattern rules and infix filenames we get something like a “filename language”. We describe the analyses we want to run and then have <em>Make</em> figure out the details.</p>
<blockquote>
<h4 id="practice-5">Practice</h4>
<p>Update your drawing of the dependency graph.</p>
</blockquote>
<h2 id="built-in-testing">Built-in Testing</h2>
<p>It’s a Good Idea to check your analysis against some form of ground truth. The simplest version of this is a well-defined dataset that you can reason about independent of your code. Let’s make just such a dataset. Let’s write a book!</p>
<p>Into a file called <code>books/test.txt</code> add something like this:</p>
<pre><code>My Book
By Me

This is a book that I wrote.

The END
</code></pre>
<p>We don’t need software to count all of the words in this book, and we can probably imagine exactly what a barplot of the count would look like. If the actual result doesn’t look like we expected, then there’s probably something wrong with our analysis. Testing your scripts with this tiny book is computationally cheap, too.</p>
<p>Let’s try it out!</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">make</span> fig/test.lower.counts.png
<span class="kw">less</span> data/test.lower.counts.tsv</code></pre></div>
<p>Does your counts data match what you expected?</p>
<p>We should run this test for just about every change we make, to our scripts or to our Makefile. We’re going to do that a <em>lot</em> so we’ll make it as easy as possible.</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dv">test:</span><span class="dt"> fig/test.lower.counts.png</span>

<span class="ot">.PHONY:</span><span class="dt"> test clean all</span></code></pre></div>
<p>You could even add the <code>test</code> phony target as the first thing in your Makefile. That way just calling <code>make</code> will run your tests.</p>
<blockquote>
<h4 id="practice-6">Practice</h4>
<p>Add a cleanup target called <code>testclean</code> which is specific for the outputs of your test run.</p>
</blockquote>
<p>Commit your changes, including <code>books/test.txt</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> add Makefile
<span class="kw">git</span> add -f books/test.txt
<span class="kw">git</span> commit -m <span class="st">&quot;Add pipeline testing recipe and book.&quot;</span></code></pre></div>
<h2 id="review-version-control">Review: version control</h2>
<p>We have been following three guiding principles in our use of version control during this lesson.</p>
<ol type="1">
<li><p>Use it (always).</p>
<p>Version control is a Good Idea and should be used for any files which describe your pipeline. This includes notes/documentation/TODOs, scripts, and the Makefiles themselves.</p></li>
<li><p>Don’t version control raw or processed data which can be recreated.</p>
<p>Raw data stays raw and data cleanup should be part of the pipeline. Because of this, backing up your data is imperative, but version control is not usually the best way to do so. Consider adding a recipe which downloads raw data using <code>wget</code> or <code>curl</code>.</p>
<p>One exception would be test or example data. These should be version controlled, as they are subject to change as testing is adapted to the evolving pipeline.</p>
<p>Metadata should also be version controlled, since the format and composition of the metadata is intimately linked with the analysis pipeline itself.</p></li>
<li><p>Aim to commit “atomic” changes to your pipeline.</p>
<p>This means you should usually run <code>make test</code> before committing your changes so that regressions don’t need to be fixed in subsequent commits. Co-dependent updates to metadata, documentation, and testing should be included in the same commit. In a perfect world, <code>make all</code> should work, and documentation should be up to date, regardless of what revision has been checked out. Excessive application of this principle is ill advised.</p>
<p>A more common problem are behemoth commits which make large numbers of unrelated changes. In general, a single sentence commit message should be able to summarize all of the changes in a commit.</p></li>
</ol>
<h2 id="exercises-left-to-the-reader">Exercises left to the reader</h2>
<blockquote>
<h4 id="challenge-3">Challenge</h4>
<p>Download your data using <em>Make</em>.</p>
</blockquote>
<blockquote>
<h4 id="challenge-4">Challenge</h4>
<p>Bootstrap your local setup using <em>Make</em>.</p>
</blockquote>
</body>
</html>
